linear regression : statistical algorithm that model relationship between dependent and independent variables. linear regression finds best-fitting linear equation predicts dependent or target variables
Ordinary least squares most common method used in linear regression aim to minimize error blw observed data point and predicted values(Ridge regression-imporve performance of lr
, Lasso regression->increase model interpretation, Elastic net combines ridge and lasso, Non negative least squares regression variant-> making ideal for Non negative values such as price or temp

Logistic regression: Binary classification problems. refer class or category, relationship blw independent variables and probability of observation belonging to particular class.it applies a user defined threshold(hyperparameter)
Logistic used for decision making data into two classes.such as whether to invest in certain stock,buy or sell a 
business or make medical diagnosis.



Decision trees :provides way make systematic decisions using flowchart like set binary decisions. It is hierarchical,branching tree like structure 
if condition1 and condition2 ... and condition3 then outcome
Decision trees used both classification and regression tasks. making decission at each node
starting with labeled data and potential features for branching. divided into subsets hold specific feature sets. 
ex-gini metric lower gini value higher quality.
limitation DT : can overly complex, leading to overfitting. 
overfitting can controlled through methods such as tree pruning, setting a minimum sample count for leaf nodes or limiting the tree's depth

Support vecotor machines(SVMs): a supervised ml algo use classification and regression task.operates on principle of finding a hyperplane or line in two -dimension space that separates two classes of data points.
discriminative classifier solve both classification and regression problems as supervised algorithm, svm requires labeled data, model train on subset data 
SVM classifier are well known for their abiltiy to identify hand-written digits
use for facial recoginition, image segmentation(differentiating organs or tssues in MRI) life expectancy, and expected return on investment(ROI) in financial industry
Linear SVM: main objective to find line or plane that best separates classes in target variable from each other.
Kernel SVM: Many real world problem cannot divided into classes by simple line.svm applied using "kernel trick" uses curved lines insted of strainght lines to separate the class.iris use linear kernel and linearsvm
SVM can high accuracy, working well with high-dimensional data, low sensitivity outliers.

K-nearest neighbors(KNN) : train data based on label target classes. algo can conceivably use lidar images distinguish 3D human and 2D pictures
KNN- prevalent in many sectors, such as healthcare(for disease prediction), finance(credit scoring), and e-commerce(for rcommendation systems)
KNN classification (predict categories): uses knn algotithm to categorize labeled data point by analyzing the categories labeled data point by analyzing categories of K nearest neighbors in feature space 
KNN classification has seen widespred use in image recognition where image classified based on feature of similar images in dataset.
voice recoginition system use knn to classify voice command by comparing them to known voice patterns
KNN classify genes into dfferent functional cateories in bilogical sciences and genetics.

KNN regression: class becomes very large(continous value)
real estate: predict price of house based on feature(area, nu bedroom, location) knn reggression used averageing the prices of Kmost similar house
stock market forcasting: historical stock price movements can inform future price predictions
Weithted averaging: closer neighbors can give more weight in averaging process


EValuation matrics for classification
Accuracy: straightforward metric represent ratio of correctly predcted instances total instances in dataset. beneficail when class distribution is blanced 
in case class is imbalance accuracy can misleading for instance, 95% samples belong to classA and 5% belong to classB model predicting everything as classA still accuracy 95%

Precision and recall: metric measures accuracy of positive prediction wile recall measures the ration of positive instance 
precision and recall especially important when false positive and false negatives carry different costs.for flase negative(disease present but not detected) more dangerous in medical test than false positive(disease absent but indicated as present)

Confusion matrix : is table used to describe performance of classification model on set of data true values known four value TP,FP,TN,FN 
true positives and true negatives indicate correct classifications, where false postivies and false negatives indicate errors, ture positive would disease present and detected while true negative would be disease absent and not detected as present


Area Under the curve-receiver operating characteristic(AUC-ROC): curve plots true positive rate(recall) against false positive rate
AUC represent area under ROC give scalar value, indicates model ability to distinguish between positive and negtive class
AUC-ROC useful dealing with dataset with class imabalance. AUC value 0.5 suggests no discrimination(equivalent to random guessing) 
value 1 indicates perfect discrimination. ex- credit card transaction most lgitimate very few fraudulent, which represents imabalance two transaction classes.


Evaluation matrics for regression: examine relation blw two or more variable of interest.
R-squared(R2): coeffieient determination, quantifies proportion of variance in dependent variable that predictable from independent variables 
range(0-1) 1 INDICates regression predictions perfectly fit data R2 suggest better fit, doesn't always mean better model, especially if model is overfitting.
Mean squared error(MSE): av squared differences blw observed and predicted values.MSE emphasize more significant errors over smaller ones
since squares residuals.means sensitive to outliers lower mse generally consider better
Mean absolute error(MAE): calcualte avg absolute difference blw observed and predicted values
MAE treates all errors equally, so it is less sensitive to outliers compared to Mse similar to MSE a lower MAE indicates better model fit data



Natuaral Language Processing (NLP):bridge blw intricate nuances of human language and analytical prowess data science.
NLP use AI focuses on teaching computers to understand,intrpret, and interact with human language way that both meaningful and useful. 
Computer science: programmer design and develop NLP algotithms to efficeintly process and analyze vast volumes of text data.these algo enable machine to perform text classification, sentimetn analysis and Language translation task
Liguistics: linguistics, study of languages, brings valuable insights to NLP , programmers developers use these insights to help NLP system understand and work with text and speech data
Machine learning: programmer use ml to train deep learning models to learn and adapt language patterns.NLP-driven model have signigicantly advanced text understanding and response
Data science: collecting, analyzing preprocessing, and structuring vast amount ot textual dat for analysis. NLP leverages data science technique to train model derive insights from textdat

Practical application and task NLP
Text understanding: NLP systems use text understanding analyze and intrpret meaning of textual data.
Language translation: NLP use convert text or speech from one language to another. NLP powwered translation system apply advanced techniques to ensure accuracy and fluency translated content, helping people from different linguistic backgrounds communicate.
Sentiment analysis: application of NLP help business analyze customer sentiment and opinion expressed text data such as social media post, review or comments.allow businesses to understand whether customer express positive negative aor neutral sentiment
Speech recognition: NLP converts spoken language into text, process widely used voice assistants and transcription services. NLP also improves accessibility individuals with disabliltes


two spect NLP 
Natural language understanding(NLU):enable computer to understand interpret human language.It involves task as text comprehension, language modeling,sentiment analysis and recoginition. NLU allow NLP systems to grasp meaning, context  and behind text or speech
Natural language generation(NLG): focuses on generation of human like text or speech by computers. NLG systems transform structuted data into coherent and contextually relevant languages.
this use various application including text summarization, language translation, chatbots, voice assistants, and personalized email to enable machine to speak to humans and natuarally and understandably

Common programs using NLP
Microsoft word: nlp feature like spell check, grammar check, and autocorrection. It also offers suggestion for improved sentence structure and readabilty
Google search: engine use NLP algorithm to understand user queries and provide relevant search results. Feature like google autocomplete and featured snippets also use nLP
social media platforms: like facebook and linkedin use NLP for content recommendation, sentiment analysis and trending topic identification.
voice assistants:like apple siri,amazon's alexa, google assistant rely on NLP understand and respond to spoken language commmand and questions.
Customer support chatbots: service use chatbot nLP capabilities provide instant customer support, answer frequently asked questions and assist users with inquiries.
Content recommendation systems: Streaming platforms like Netflix and music service like spotify use NLP for content recommendation, suggesting movies, shows, or music base on preferences
Healthcare information systems: NLP usd heathcare information system process medical records extract patient information and assist in clinical decision
Virtual learning environments: automated grading ,personalized course recomendation nlp.

Ambiguity: ambiguous, word and phrases have multiple meaning and association depending on contect how the word is used. NLP models use contextual information and surrounding words to disambguate.
Lack of context: struggle with maintaining context in long conversation or understanding subtle nuancess. Models with memory mechanisms, like transformers, help capture context over longer text
Bias and fairness: model inherit biases from training data, leading to biased or unfair outcomes.Addressing bias requries diverse and representative training data,ongoing monitoring, fairness-aware model design mitigate and correct biases.


Tool and techniques include NLP
Tokenization: Breaks text into individual words or tokens,forming basis for most NLP tasks.
Stemming and lemmatization: words to root forms,aiding text analysis and rducing vocabulary variations.
Part of speech tagging(POS): grammatical labels to words,helping syntax analysis and understanding sentence structure
Named entity recognition(NER): categorize named entities,such as names people,place and businesses in text.
Sentiment analysis: tool assesses emotional tone expressed text and often used for sentiment classification,such as positive,negative or neutral.
Text classification:text into predefined classses or labels,such as spam detection or topic classification
Machine translation:like google translate,NLP techniques translate text blw languages.
Pre-trained language model:Large scale such as google BERT and openAI chatGPT, revolutionized NLP providing deep contectual understanding and generating human like text.


NLP libraries and framework
NLTK : comprehensice python library for NLP, contain many tool and resources task like tokenization,stemming,lemmatization,pos tagging.
spaCy: fast and efficient python library for NLP. provids pre-trained models and supporttask like tokenization,pos tagging, and NER.spaCy known for speed and production-readiness.
Transformers from Hugging Face:Provides state-of-the-art  pre-trained language models shuch as google BERT.It's widely used various NLP task text classification,language generation , translation
Standford NLP:tool and model including tokenization,pos tagging and NER.It known for its high quality models and accuracy ofeten used for academic and research purposes.
AllenNLP: deep learing framework specifically designed for NLP research. provides pre-built components for building and evaluting NLP models

Text acquisition->Text preprocessing_>sentence structure and interpretation_>Numerical representaion->Machine training and accuracy checks->Application development
